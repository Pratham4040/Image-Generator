{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratham4040/Image-Generator/blob/main/GPT_SoVITS_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-SoVITS-WebUI\n",
        "A Few-shot & Zero-shot Text-to-Speech WebUI.\n",
        "\n",
        "\n",
        "[General GPT-SoVITS Guide](https://rentry.co/GPT-SoVITS-guide#3-initialize-dataset)\n",
        "\n",
        "### Credits:\n",
        "\n",
        "- Original Project & Colab done by [GPT-SoVITS Team](https://github.com/RVC-Boss/GPT-SoVITS/graphs/contributors)\n",
        "\n",
        "- Port made by [Nick088](https://linktr.ee/Nick088)\n",
        "\n",
        "- Testing/Tweaks done by [vulkanitexd](https://discord.com/users/984567398826917918)"
      ],
      "metadata": {
        "id": "_oJOFXTQ0OhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare the Environment\n",
        "#@markdown It git clones the repository.\n",
        "\n",
        "# get the repo\n",
        "!git clone https://github.com/RVC-Boss/GPT-SoVITS\n",
        "%cd GPT-SoVITS"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RvOEAQx-9wBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bdbafe-a523-4ab7-924a-a627f480a7bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GPT-SoVITS'...\n",
            "remote: Enumerating objects: 4289, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 4289 (delta 45), reused 23 (delta 23), pack-reused 4232 (from 2)\u001b[K\n",
            "Receiving objects: 100% (4289/4289), 12.60 MiB | 10.80 MiB/s, done.\n",
            "Resolving deltas: 100% (2481/2481), done.\n",
            "/content/GPT-SoVITS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (OPTIONAL) Mount Google Drive\n",
        "\n",
        "#@markdown This will create a `GPT-SoVITS` folder in [your Google Drive](https://drive.google.com/drive/u/0/home), that can be used to put things like your model dataset, but you have to **manually put the full path** which can be `/content/drive/MyDrive/GPT-SoVITS/YourDatasetHere`\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the parent directory path\n",
        "parent_dir = '/content/drive/MyDrive/GPT-SoVITS'\n",
        "\n",
        "# Create the parent directory if it doesn't exist\n",
        "if not os.path.exists(parent_dir):\n",
        "    os.mkdir(parent_dir)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zleh7bJOq7DX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3d2161ed-0f18-4c6d-e5b5-3e4f0519cf00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f8769a85c1c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the parent directory path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Conda\n",
        "#@markdown Conda will make the session crash/restart, it's normal, just run the following cells after.\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/miniconda/Miniconda3-py39_24.11.1-0-Linux-x86_64.sh\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fMsdGH8AlQgn",
        "outputId": "ae285073-865b-4e3f-afcb-b92abe9786bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://repo.anaconda.com/miniconda/Miniconda3-py39_24.11.1-0-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:27\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install requirements\n",
        "#@markdown Will take alot of time..\n",
        "\n",
        "#@markdown The runtime will restart itself, it's normal.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "%cd /content/GPT-SoVITS/\n",
        "!bash install.sh\n",
        "\n",
        "# fix packages asr models japanese/english (whisper)\n",
        "!pip install ctranslate2==4.4.0\n",
        "\n",
        "# fix https://github.com/RVC-Boss/GPT-SoVITS/issues/1715\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# fix for issue in inference\n",
        "!pip install -q ipykernel\n",
        "\n",
        "# fix train gpt\n",
        "!pip install torchmetrics==1.5\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Installed the requirements!\")\n",
        "\n",
        "time.sleep(5)\n",
        "# restart runtime\n",
        "import os\n",
        "os._exit(0)"
      ],
      "metadata": {
        "id": "afNtr2lXyuKQ",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0102fc3-e2d0-4ba6-c15f-2781fc7a5b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed the requirements!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pretrained Models\n",
        "#@markdown gpt so vits v1 & v2 pretrains + uvr5 weights + chinese asr. (english/japanese asr, faster whisper, should be automatically installed when using it for ASR in the UI)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "\n",
        "# gpt so vits pretrains\n",
        "\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS/ gptsovits_pretrains_temp\n",
        "\n",
        "!mv gptsovits_pretrains_temp/* GPT-SoVITS/GPT_SoVITS/pretrained_models/\n",
        "\n",
        "!rm -rf gptsovits_pretrains_temp\n",
        "\n",
        "\n",
        "# uvr5 weights\n",
        "\n",
        "!git clone https://huggingface.co/Delik/uvr5_weights uvr5_weights_temp\n",
        "\n",
        "!mv uvr5_weights_temp/* GPT-SoVITS/tools/uvr5/uvr5_weights\n",
        "\n",
        "!rm -rf uvr5_weights_temp\n",
        "\n",
        "\n",
        "# Chinese ASR models\n",
        "\n",
        "%cd /content/GPT-SoVITS/tools/asr/models\n",
        "!git clone https://www.modelscope.cn/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch.git\n",
        "\n",
        "# English/Japanese ASR should be automatically downloaded.\n",
        "\n",
        "clear_output()\n",
        "print(\"Downloaded!\")"
      ],
      "metadata": {
        "id": "ym6l8aAiBjKj",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef96c3a-7121-429b-cb83-811f61b0164c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run UI\n",
        "\n",
        "#@markdown The first run may take more time as it will download the g2pw model.\n",
        "\n",
        "#@markdown The type of tunnel you wanna use for seeing the public link, so that if one of them is down, you can use the other one.\n",
        "Tunnel = \"Gradio\" #@param [\"Gradio\", \"Ngrok\", \"Cloudflare\", \"LocalTunnel\", \"Horizon\"]\n",
        "\n",
        "#@markdown Also when using Ngrok ,Cloudflare, LocalTunnel, or Horizon, you need to wait for the Local URL to appear, and only after that click on the Public URL which is above. Plus, you have to open UVR in the GPT-SoVITS UI before opening the Public URL.\n",
        "\n",
        "\n",
        "#@markdown Use the following option **only if you chose Ngrok** as the Tunnel, **You need to be a paid ngrok member** as it needs more than 3 tunnels (there are 4 ports):\n",
        "\n",
        "#@markdown You can get the Ngrok Tunnel Authtoken here: https://dashboard.ngrok.com/tunnels/authtokens/new.\n",
        "\n",
        "ngrok_tunnel_authtoken = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown Use the following option **only if you chose Horizon** as the Tunnel:\n",
        "\n",
        "#@markdown You can get the Horizon ID here: https://hrzn.run/dashboard/ , login, on the 2nd step, it shows an `hrzn login YOUR_ID`, you need to copy that id.\n",
        "\n",
        "horizon_id = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "%cd /content/GPT-SoVITS/\n",
        "\n",
        "\n",
        "if Tunnel == \"Gradio\":\n",
        "  %env is_share = True\n",
        "elif Tunnel == \"Ngrok\":\n",
        "  %env is_share = False\n",
        "  !pip install pyngrok\n",
        "  from pyngrok import ngrok\n",
        "  ngrok.set_auth_token(ngrok_tunnel_authtoken)\n",
        "  gptsovits_tunnel = ngrok.connect(9874, bind_tls=True)\n",
        "  uvr_tunnel = ngrok.connect(9873, bind_tls=True)\n",
        "  inference_tunnel = ngrok.connect(9872, bind_tls=True)\n",
        "  proofreading_tunnel = ngrok.connect(9871, bind_tls=True)\n",
        "  print(\"GPT-SoVITS Tunnel Public URL:\", gptsovits_tunnel.public_url)\n",
        "  print(\"UVR Tunnel Public URL:\", uvr_tunnel.public_url)\n",
        "  print(\"Inference Tunnel Public URL:\", uvr_tunnel.public_url)\n",
        "  print(\"Proofreading Tunnel Public URL:\", proofreading_tunnel.public_url)\n",
        "elif Tunnel == \"Cloudflare\":\n",
        "  %env is_share = False\n",
        "  # download cloudflare\n",
        "  !curl -LO https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "  !dpkg -i cloudflared-linux-amd64.deb\n",
        "  !rm -rf nohup.out\n",
        "  import time\n",
        "  # Run cloudflare\n",
        "  # gpt so vits\n",
        "  !nohup cloudflared tunnel --url localhost:9874 &\n",
        "  time.sleep(7)\n",
        "  # uvr\n",
        "  !nohup cloudflared tunnel --url localhost:9873 &\n",
        "  time.sleep(7)\n",
        "  # inference\n",
        "  !nohup cloudflared tunnel --url localhost:9872 &\n",
        "  time.sleep(7)\n",
        "  # proofreading\n",
        "  !nohup cloudflared tunnel --url localhost:9871 &\n",
        "  clear_output()\n",
        "  time.sleep(7)\n",
        "  # Find and print the Cloudflare URL with a prefix\n",
        "  cloudflare_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.trycloudflare\\.com\" nohup.out\n",
        "  print(f\"GPT-SoVITS Tunnel Public URL: {cloudflare_url[0]}\")\n",
        "  print(f\"UVR Tunnel Public URL: {cloudflare_url[1]}\")\n",
        "  print(f\"Inference Tunnel Public URL: {cloudflare_url[2]}\")\n",
        "  print(f\"Proofreading Tunnel Public URL: {cloudflare_url[3]}\")\n",
        "elif Tunnel == \"LocalTunnel\":\n",
        "  %env is_share = False\n",
        "  # install\n",
        "  !npm install -g localtunnel\n",
        "  import time\n",
        "  import urllib\n",
        "  # run localtunnel\n",
        "  # gptsovits\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9874 >> url.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  print(f\"GPT-SoVITS Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  # uvr\n",
        "  with open('url2.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9873 >> url2.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url2.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  print(f\"UVR Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  # inference\n",
        "  with open('url3.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9872 >> url3.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url3.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  print(f\"Inference Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  # proofreading\n",
        "  with open('url4.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9871 >> url4.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url4.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  print(f\"Proofreading Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "\n",
        "  print(f'LocalTunnels Password: {endpoint_ip}')\n",
        "elif Tunnel == \"Horizon\":\n",
        "  # install\n",
        "  !npm install -g @hrzn/cli\n",
        "  # login\n",
        "  !hrzn login $horizon_id\n",
        "  # run horizon\n",
        "  # gptsovits\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9874 >> url.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  print(f\"GPT-SoVITS Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "  # uvr\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9873 >> url2.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url2.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url2.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  print(f\"UVR Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "  # inference\n",
        "  with open('url3.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9872 >> url3.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url3.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url3.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  print(f\"Inference Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "  # proofreading\n",
        "  with open('url4.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9871 >> url4.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url4.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url4.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  print(f\"Proofreading Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "\n",
        "import subprocess\n",
        "!python webui.py"
      ],
      "metadata": {
        "id": "Otq5d5-Z7xZL",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9cab10-18d0-4ae8-f119-af53e3c3d0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPT-SoVITS\n",
            "env: is_share=True\n",
            "/bin/bash: /usr/local/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://634316aae28a117b96.gradio.live\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/inference_webui.py \"Auto\"\n",
            "loading sovits_v1 <All keys matched successfully>\n",
            "Running on local URL:  http://0.0.0.0:9872\n",
            "Running on public URL: https://3aa15b99392c9b178f.gradio.live\n",
            "Actual Input Reference Text: Open it up, Show mw what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "[\u001b[36m2025-02-15 15:25:34,499\u001b[0m][\u001b[32mINFO\u001b[0m] - Downloading https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin to lid.176.bin (125.2M)\u001b[0m\n",
            "INFO:robust_downloader.downloader:Downloading https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin to lid.176.bin (125.2M)\n",
            "100% 125M/125M [00:03<00:00, 38.3MB/s]\n",
            "['OPENITUP,SHOWMWWHATINSIDE.WELL,WHATDOWEHAVEHERE.']\n",
            "['en']\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko。\n",
            "['HELLOIAMYAEMIKO.']\n",
            "['en']\n",
            "Processed text from the frontend (per sentence): H E L L O I A M Y A E M I K O.\n",
            " 34% 505/1500 [00:36<01:18, 12.64it/s]T2S Decoding EOS [134 -> 641]\n",
            " 34% 506/1500 [00:36<01:12, 13.73it/s]\n",
            "4.932\t11.527\t36.851\t29.106\n",
            "Actual Input Reference Text: Open it up, Show mw what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko。\n",
            "['HELLOIAMYAEMIKO.']\n",
            "['en']\n",
            "Processed text from the frontend (per sentence): H E L L O I A M Y A E M I K O.\n",
            "  4% 67/1500 [00:05<01:17, 18.52it/s]T2S Decoding EOS [134 -> 203]\n",
            "  5% 68/1500 [00:05<01:48, 13.14it/s]\n",
            "1.751\t0.006\t5.180\t3.075\n",
            "Actual Input Reference Text: Open it up, Show mw what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko.\n",
            "Processed text from the frontend (per sentence): Hello I am yae miko.\n",
            "  4% 57/1500 [00:03<01:36, 14.99it/s]T2S Decoding EOS [134 -> 192]\n",
            "  4% 57/1500 [00:03<01:40, 14.34it/s]\n",
            "1.909\t0.004\t3.981\t3.544\n",
            "Actual Input Reference Text: Open it up, Show mw what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko.\n",
            "Processed text from the frontend (per sentence): Hello I am yae miko.\n",
            "  3% 43/1500 [00:02<01:21, 17.96it/s]T2S Decoding EOS [134 -> 179]\n",
            "  3% 44/1500 [00:03<01:42, 14.20it/s]\n",
            "1.715\t0.003\t3.102\t2.075\n",
            "Actual Input Reference Text: Open it up, Show mw what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko.\n",
            "Processed text from the frontend (per sentence): Hello I am yae miko.\n",
            "1.897\t0.004\t0.000\t1.984\n",
            "loading sovits_v2 <All keys matched successfully>\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko.\n",
            "Processed text from the frontend (per sentence): Hello I am yae miko.\n",
            "2.468\t0.005\t0.000\t2.489\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Hello I am yae miko\n",
            "Actual Input Target Text (after sentence segmentation): Hello I am yae miko\n",
            "Actual Input Target Text (per sentence): Hello I am yae miko.\n",
            "Processed text from the frontend (per sentence): Hello I am yae miko.\n",
            "  4% 55/1500 [00:03<01:19, 18.26it/s]T2S Decoding EOS [134 -> 190]\n",
            "  4% 55/1500 [00:03<01:38, 14.74it/s]\n",
            "1.693\t0.003\t3.736\t3.431\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought Uzumaki was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought Uzumaki was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought Uzumaki was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought Uzumaki was creepy,\n",
            "  3% 51/1500 [00:03<01:16, 19.04it/s]T2S Decoding EOS [134 -> 186]\n",
            "  3% 51/1500 [00:03<01:37, 14.94it/s]\n",
            "2.264\t0.010\t3.421\t2.285\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought Uzumaki was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought Uzumaki was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought Uzumaki was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought Uzumaki was creepy,\n",
            "2.146\t0.008\t0.000\t2.240\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought this was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought this was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought this was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought this was creepy,\n",
            "1.936\t0.003\t0.000\t2.218\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought this was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought this was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought this was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought this was creepy,\n",
            "1.738\t0.003\t0.000\t2.233\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought this was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought this was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought this was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought this was creepy,\n",
            "2.000\t0.006\t0.000\t3.041\n",
            "loading sovits_v1 <All keys matched successfully>\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought this was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought this was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought this was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought this was creepy,\n",
            "1.817\t0.003\t0.000\t3.145\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: If you thought this was creepy,\n",
            "Actual Input Target Text (after sentence segmentation): If you thought this was creepy,\n",
            "Actual Input Target Text (per sentence): If you thought this was creepy,\n",
            "Processed text from the frontend (per sentence): If you thought this was creepy,\n",
            "  3% 39/1500 [00:03<01:42, 14.31it/s]T2S Decoding EOS [134 -> 175]\n",
            "  3% 40/1500 [00:03<02:06, 11.55it/s]\n",
            "1.780\t0.004\t3.468\t1.926\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: wait till you hear about these eerie tales!\n",
            "Actual Input Target Text (after sentence segmentation): wait till you hear about these eerie tales!\n",
            "Actual Input Target Text (per sentence): wait till you hear about these eerie tales!\n",
            "Processed text from the frontend (per sentence): wait till you hear about these eerie tales!\n",
            "  4% 61/1500 [00:04<01:18, 18.26it/s]T2S Decoding EOS [134 -> 196]\n",
            "  4% 61/1500 [00:04<01:54, 12.58it/s]\n",
            "1.822\t0.004\t4.854\t2.808\n",
            "Actual Input Reference Text: Open it up, Show me what inside. Well, what do we have here.\n",
            "Actual Input Target Text: Let's explore the top 5 creepiest manga that'll keep you up at night! First up, we have Tomie by Junji Ito. Imagine a girl who just won't stay dead. Sounds chilling, right? Next, The Drifting Classroom by Kazuo Umezu. A school suddenly transported to a wasteland, with students fighting for survival. It's pure nightmare fuel! Third on the list is Gyo also by Junji Ito. Ever wondered what happens when fish grow legs and start attacking humans? Yeah, it's as creepy as it sounds. Don't forget to like and subscribe for more eerie recommendations! (pause) Stay spooky, manga fans!\n",
            "Actual Input Target Text (after sentence segmentation): Let's explore the top 5 creepiest manga that'll keep you up at night! First up, we have Tomie by Junji Ito. Imagine a girl who just won't stay dead.\n",
            " Sounds chilling, right? Next, The Drifting Classroom by Kazuo Umezu.\n",
            " A school suddenly transported to a wasteland, with students fighting for survival. It's pure nightmare fuel! Third on the list is Gyo also by Junji Ito.\n",
            " Ever wondered what happens when fish grow legs and start attacking humans? Yeah, it's as creepy as it sounds. Don't forget to like and subscribe for more eerie recommendations! (pause) Stay spooky, manga fans!\n",
            "Actual Input Target Text (per sentence): Let's explore the top 5 creepiest manga that'll keep you up at night! First up, we have Tomie by Junji Ito. Imagine a girl who just won't stay dead.\n",
            "Processed text from the frontend (per sentence): Let's explore the top five creepiest manga that'll keep you up at night! First up, we have Tomie by Junji Ito. Imagine a girl who just won't stay dead.\n",
            " 16% 243/1500 [00:17<01:26, 14.56it/s]T2S Decoding EOS [134 -> 379]\n",
            " 16% 244/1500 [00:17<01:31, 13.74it/s]\n",
            "Actual Input Target Text (per sentence):  Sounds chilling, right? Next, The Drifting Classroom by Kazuo Umezu.\n",
            "Processed text from the frontend (per sentence):  Sounds chilling, right? Next, The Drifting Classroom by Kazuo Umezu.\n",
            "  9% 137/1500 [00:08<01:21, 16.74it/s]T2S Decoding EOS [134 -> 272]\n",
            "  9% 137/1500 [00:08<01:25, 15.97it/s]\n",
            "Actual Input Target Text (per sentence):  A school suddenly transported to a wasteland, with students fighting for survival. It's pure nightmare fuel! Third on the list is Gyo also by Junji Ito.\n",
            "Processed text from the frontend (per sentence):  A school suddenly transported to a wasteland, with students fighting for survival. It's pure nightmare fuel! Third on the list is Gyo also by Junji Ito.\n",
            " 16% 247/1500 [00:17<01:26, 14.54it/s]T2S Decoding EOS [134 -> 382]\n",
            " 16% 247/1500 [00:17<01:27, 14.29it/s]\n",
            "Actual Input Target Text (per sentence):  Ever wondered what happens when fish grow legs and start attacking humans? Yeah, it's as creepy as it sounds. Don't forget to like and subscribe for more eerie recommendations! (pause) Stay spooky, manga fans!\n",
            "Processed text from the frontend (per sentence):  Ever wondered what happens when fish grow legs and start attacking humans? Yeah, it's as creepy as it sounds. Don't forget to like and subscribe for more eerie recommendations! pause Stay spooky, manga fans!\n",
            " 23% 343/1500 [00:26<01:28, 13.06it/s]T2S Decoding EOS [134 -> 478]\n",
            " 23% 343/1500 [00:26<01:28, 13.09it/s]\n",
            "1.903\t0.030\t69.837\t45.994\n"
          ]
        }
      ]
    }
  ]
}